{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task 5.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWiM0d2FRTM0"
      },
      "source": [
        "**The Sparks Foundation<br>**\r\n",
        "**Task 5 -> Traffic Signs Detection<br>**\r\n",
        "**By: Yugandhar Yelai**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtE0dJPRMOJD"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xXP8FglM2Hf"
      },
      "source": [
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/ \r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyyXYKfFNaCJ"
      },
      "source": [
        "!kaggle datasets download -d flo2607/traffic-signs-classification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D83vIYSNNe1X"
      },
      "source": [
        "!ls\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QwcWs1vNlf0"
      },
      "source": [
        "from zipfile import ZipFile\r\n",
        "file_name = \"traffic-signs-classification.zip\"\r\n",
        "\r\n",
        "with ZipFile(file_name,\"r\") as zip:\r\n",
        "  zip.extractall()\r\n",
        "  print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLDqUneMNpMh"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORLRNFefNt64"
      },
      "source": [
        "!ls myData"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ak25QKM701"
      },
      "source": [
        "**importing the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk1zJMknpSKA"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.optimizers import Adam\r\n",
        "from keras.utils.np_utils import to_categorical\r\n",
        "from keras.layers import Dropout, Flatten\r\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\r\n",
        "import cv2\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import os\r\n",
        "import pandas as pd\r\n",
        "import random\r\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JArZAb0JNKEL"
      },
      "source": [
        "**Extracting the Labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz-GM2oGd5cN"
      },
      "source": [
        "path = '.'\r\n",
        "data = pd.read_csv('labels.csv') # file with all names of classes\r\n",
        "d = dict()\r\n",
        "class_labels = dict()\r\n",
        "for dirs in os.listdir(path + '/myData'):\r\n",
        "    count = len(os.listdir(path+'/myData/'+dirs))\r\n",
        "    d[dirs+' => '+data[data.ClassId == int(dirs)].values[0][1]] = count\r\n",
        "    class_labels[int(dirs)] = data[data.ClassId == int(dirs)].values[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShMzF5HHpPiJ"
      },
      "source": [
        "path = \"myData\" # folder with all the class folders\r\n",
        "batch_size_val=50  # how many to process together\r\n",
        "epochs_val=10\r\n",
        "imageDimesions = (32,32,3)\r\n",
        "testRatio = 0.2    # if 1000 images split will 200 for testing\r\n",
        "validationRatio = 0.2 # if 1000 images 20% of remaining 800 will be 160 for validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWXvG-uuyfgv"
      },
      "source": [
        "**Importing of the Images And Spliting into trainTest Sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzZVsJgmpNGJ"
      },
      "source": [
        "\r\n",
        "count = 0\r\n",
        "images = []\r\n",
        "classNo = []\r\n",
        "myList = os.listdir(path)\r\n",
        "noOfClasses=len(myList)\r\n",
        "print(\"Total no of Classes Present:\",noOfClasses)\r\n",
        "for x in range (0,len(myList)):\r\n",
        "    myPicList = os.listdir(path+\"/\"+str(count))\r\n",
        "    for y in myPicList:\r\n",
        "        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\r\n",
        "        images.append(curImg)\r\n",
        "        classNo.append(count)\r\n",
        "    count +=1\r\n",
        "images = np.array(images)\r\n",
        "classNo = np.array(classNo)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, classNo, test_size=testRatio)\r\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validationRatio)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZDaYW65ODIP"
      },
      "source": [
        "**TO CHECK IF NUMBER OF IMAGES MATCHES TO NUMBER OF LABELS FOR EACH DATA SET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T93CHIxmpJ3t"
      },
      "source": [
        "\r\n",
        "print(\"Data Shapes\")\r\n",
        "print(\"Train\",end = \"\");print(X_train.shape,y_train.shape)\r\n",
        "print(\"Validation\",end = \"\");print(X_validation.shape,y_validation.shape)\r\n",
        "print(\"Test\",end = \"\");print(X_test.shape,y_test.shape)\r\n",
        "assert(X_train.shape[0]==y_train.shape[0]), \"The number of images in not equal to the number of lables in training set\"\r\n",
        "assert(X_validation.shape[0]==y_validation.shape[0]), \"The number of images in not equal to the number of lables in validation set\"\r\n",
        "assert(X_test.shape[0]==y_test.shape[0]), \"The number of images in not equal to the number of lables in test set\"\r\n",
        "assert(X_train.shape[1:]==(imageDimesions)),\" The dimesions of the Training images are wrong \"\r\n",
        "assert(X_validation.shape[1:]==(imageDimesions)),\" The dimesionas of the Validation images are wrong \"\r\n",
        "assert(X_test.shape[1:]==(imageDimesions)),\" The dimesionas of the Test images are wrong\"\r\n",
        "print(\"data shape \",data.shape,type(data))\r\n",
        " \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7yqXVSjOaKG"
      },
      "source": [
        "**DISPLAYING SOME SAMPLE IMAGES  OF ALL THE CLASSES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjhOt9mxpCix"
      },
      "source": [
        "num_of_samples = []\r\n",
        "cols = 5\r\n",
        "num_classes = noOfClasses\r\n",
        "fig, axs = plt.subplots(nrows=num_classes, ncols=cols, figsize=(5, 300))\r\n",
        "fig.tight_layout()\r\n",
        "for i in range(cols):\r\n",
        "    for j,row in data.iterrows():\r\n",
        "        x_selected = X_train[y_train == j]\r\n",
        "        axs[j][i].imshow(x_selected[random.randint(0, len(x_selected)- 1), :, :], cmap=plt.get_cmap(\"gray\"))\r\n",
        "        axs[j][i].axis(\"off\")\r\n",
        "        if i == 2:\r\n",
        "            axs[j][i].set_title(str(j)+ \"-\"+row[\"Name\"])\r\n",
        "            num_of_samples.append(len(x_selected))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_wUkWTDOnXk"
      },
      "source": [
        "**DISPLAYING A BAR CHART SHOWING NO OF SAMPLES FOR EACH CATEGORY**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbmUeIP5pAyK"
      },
      "source": [
        "plt.figure(figsize=(12, 4))\r\n",
        "plt.bar(range(0, num_classes), num_of_samples)\r\n",
        "plt.title(\"Distribution of the training dataset\")\r\n",
        "plt.xlabel(\"Class number\")\r\n",
        "plt.ylabel(\"Number of images\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIRM8y7pO0Oc"
      },
      "source": [
        "**PreProcessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX97Tywho9wd"
      },
      "source": [
        "def grayscale(img):\r\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\r\n",
        "    return img\r\n",
        "def equalize(img):\r\n",
        "    img =cv2.equalizeHist(img)\r\n",
        "    return img\r\n",
        "def preprocessing(img):\r\n",
        "    img = grayscale(img)     # CONVERT TO GRAYSCALE\r\n",
        "    img = equalize(img)      # STANDARDIZE THE LIGHTING IN AN IMAGE\r\n",
        "    img = img/255            # TO NORMALIZE VALUES BETWEEN 0 AND 1 INSTEAD OF 0 TO 255\r\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gTlp8pNo7Vp"
      },
      "source": [
        "X_train=np.array(list(map(preprocessing,X_train)))  # TO IRETATE AND PREPROCESS ALL IMAGES\r\n",
        "X_validation=np.array(list(map(preprocessing,X_validation)))\r\n",
        "X_test=np.array(list(map(preprocessing,X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl5PS3KJo5MC"
      },
      "source": [
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\r\n",
        "X_validation=X_validation.reshape(X_validation.shape[0],X_validation.shape[1],X_validation.shape[2],1)\r\n",
        "X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFHSUNUFPEDq"
      },
      "source": [
        "**Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwPHBE8Lo21A"
      },
      "source": [
        "dataGen= ImageDataGenerator(width_shift_range=0.1,   # 0.1 = 10%     IF MORE THAN 1 E.G 10 THEN IT REFFERS TO NO. OF  PIXELS EG 10 PIXELS\r\n",
        "                            height_shift_range=0.1,\r\n",
        "                            zoom_range=0.2,  # 0.2 MEANS CAN GO FROM 0.8 TO 1.2\r\n",
        "                            shear_range=0.1,  # MAGNITUDE OF SHEAR ANGLE\r\n",
        "                            rotation_range=10)  # DEGREES\r\n",
        "dataGen.fit(X_train)\r\n",
        "batches= dataGen.flow(X_train,y_train,batch_size=20)  # REQUESTING DATA GENERATOR TO GENERATE IMAGES  BATCH SIZE = NO. OF IMAGES CREAED EACH TIME ITS CALLED\r\n",
        "X_batch,y_batch = next(batches)\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNH40aNpPRGH"
      },
      "source": [
        "**AUGMENTED IMAGE SAMPLES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUPN_Zqgo0fd"
      },
      "source": [
        "fig,axs=plt.subplots(1,15,figsize=(20,5))\r\n",
        "fig.tight_layout()\r\n",
        " \r\n",
        "for i in range(15):\r\n",
        "    axs[i].imshow(X_batch[i].reshape(imageDimesions[0],imageDimesions[1]))\r\n",
        "    axs[i].axis('off')\r\n",
        "plt.show()\r\n",
        " \r\n",
        " \r\n",
        "y_train = to_categorical(y_train,noOfClasses)\r\n",
        "y_validation = to_categorical(y_validation,noOfClasses)\r\n",
        "y_test = to_categorical(y_test,noOfClasses)\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "As6eVQiKPcNR"
      },
      "source": [
        "**CONVOLUTION NEURAL NETWORK(CNN) MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8fRtuC4oxgY"
      },
      "source": [
        "def myModel():\r\n",
        "    no_Of_Filters=60\r\n",
        "    size_of_Filter=(5,5) # THIS IS THE KERNEL THAT MOVE AROUND THE IMAGE TO GET THE FEATURES.\r\n",
        "                         # THIS WOULD REMOVE 2 PIXELS FROM EACH BORDER WHEN USING 32 32 IMAGE\r\n",
        "    size_of_Filter2=(3,3)\r\n",
        "    size_of_pool=(2,2)  # SCALE DOWN ALL FEATURE MAP TO GERNALIZE MORE, TO REDUCE OVERFITTING\r\n",
        "    no_Of_Nodes = 500   # NO. OF NODES IN HIDDEN LAYERS\r\n",
        "    model= Sequential()\r\n",
        "    model.add((Conv2D(no_Of_Filters,size_of_Filter,input_shape=(imageDimesions[0],imageDimesions[1],1),activation='relu')))  # ADDING MORE CONVOLUTION LAYERS = LESS FEATURES BUT CAN CAUSE ACCURACY TO INCREASE\r\n",
        "    model.add((Conv2D(no_Of_Filters, size_of_Filter, activation='relu')))\r\n",
        "    model.add(MaxPooling2D(pool_size=size_of_pool)) # DOES NOT EFFECT THE DEPTH/NO OF FILTERS\r\n",
        " \r\n",
        "    model.add((Conv2D(no_Of_Filters//2, size_of_Filter2,activation='relu')))\r\n",
        "    model.add((Conv2D(no_Of_Filters // 2, size_of_Filter2, activation='relu')))\r\n",
        "    model.add(MaxPooling2D(pool_size=size_of_pool))\r\n",
        "    model.add(Dropout(0.5))\r\n",
        " \r\n",
        "    model.add(Flatten())\r\n",
        "    model.add(Dense(no_Of_Nodes,activation='relu'))\r\n",
        "    model.add(Dropout(0.5)) # INPUTS NODES TO DROP WITH EACH UPDATE 1 ALL 0 NONE\r\n",
        "    model.add(Dense(noOfClasses,activation='softmax')) # OUTPUT LAYER\r\n",
        "    # COMPILE MODEL\r\n",
        "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\r\n",
        "    return model\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLOAhiQ2PjUF"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7po7an8opX8_"
      },
      "source": [
        "model = myModel()\r\n",
        "print(model.summary())\r\n",
        "history=model.fit_generator(dataGen.flow(X_train,y_train,batch_size=batch_size_val),epochs=epochs_val,validation_data=(X_validation,y_validation),shuffle=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ergH0XTcPptz"
      },
      "source": [
        "**Visualize the CNN model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRG6BZ76xJSY"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\r\n",
        "plot_model(model, show_layer_names=True, show_shapes =True, to_file='model.png', dpi=350)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H5x06rhP0Jg"
      },
      "source": [
        "**Ploting the Graphs of the trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BVKJtmMeHMw"
      },
      "source": [
        "plt.figure(1)\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.legend(['training','validation'])\r\n",
        "plt.title('loss')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.figure(2)\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.legend(['training','validation'])\r\n",
        "plt.title('Acurracy')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.show()\r\n",
        "score =model.evaluate(X_test,y_test,verbose=0)\r\n",
        "print('Test Score:',score[0])\r\n",
        "print('Test Accuracy:',score[1])\r\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2sNVwL5P9Yb"
      },
      "source": [
        "**Saving the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8xtRXKqrH3L"
      },
      "source": [
        "model.save(\"final_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJlaqYlSQEC9"
      },
      "source": [
        "**Final Prediction (RESULT)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "civP2CyNry11"
      },
      "source": [
        "imgOrignal = cv2.imread(\"testing/image5.jpg\")\r\n",
        "font = cv2.FONT_HERSHEY_COMPLEX\r\n",
        "img = np.asarray(imgOrignal)\r\n",
        "img = cv2.resize(img, (32, 32))\r\n",
        "img = preprocessing(img)\r\n",
        "plt.imshow(img)\r\n",
        "img = img.reshape(1, 32, 32, 1)\r\n",
        "predictions = model.predict(img)\r\n",
        "probabilityValue =np.amax(predictions)\r\n",
        "print(\"\\tClass-->\",class_labels[np.argmax(predictions)])\r\n",
        "print(\"\\tProbability--->\",round(probabilityValue*100,2),\"%\")\r\n",
        "imgOrignal = cv2.cvtColor(imgOrignal,cv2.COLOR_BGR2RGB)\r\n",
        "plt.imshow(imgOrignal)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2UquEKsrXjT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}